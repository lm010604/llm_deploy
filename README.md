# LLaMA Model Deployment Optimization

This repository contains the code and resources used to optimize the deployment of LLaMA 3.1 models, specifically the 8b and 70b variants. The project was conducted during my Summer Internship at the Hong Kong Productivity Council from June to August 2024. The primary goal was to test various NVIDIA GPU configurations and conduct performance testing to identify the most cost-efficient deployment strategy.

